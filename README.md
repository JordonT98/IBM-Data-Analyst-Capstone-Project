# IBM Data Analyst Capstone Project

### Scenario 1
In this scenario, I collected job opening data for technologies like Java, Python, MySQL, C++, and C# using the GitHub Jobs API.
This included data collection through APIs and also involved web scraping techniques to gather additional relevant information. 
Following data collection, I explored the datasets to understand their structure and contents, facilitating further analysis.

#### File Names

•	Collecting Data Using APIs

•	Collecting Data Using Web Scraping

•	Web Scraping Review Lab

•	Explore the Data Set


### Scenario 2

Data Wrangling techniques will be used to perform the following tasks:

Data wrangling techniques will be utilized to achieve the following tasks: Identifying duplicate rows in the dataset, 
removing duplicate rows from the dataframe, determining the number of missing values for all columns, 
obtaining the value counts for the "Employment" column, and normalizing the data using two existing columns. 

#### File Names

• Data Wrangling


### Scenario 3



### Scenario 4

